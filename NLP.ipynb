{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing (NLP)\n",
    "\n",
    "### Word Embeddings (Word Vectors)\n",
    "\n",
    "A mapping words from a vocabulary into a low-dimensional space, where words with similar meanings are close together. \n",
    "\n",
    "Use ConceptNet Numberbatch for their pre-trained word vectors to get used to its properties.\n",
    "\n",
    "They use h5 as the format. Need to install `h5py` if haven't.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download word vectors\n",
    "from urllib.request import urlretrieve\n",
    "import os\n",
    "\n",
    "if not os.path.isfile('datasets/mini.h5'):\n",
    "    print(\"Downloading Conceptnet Numberbatch word embeddings...\")\n",
    "    conceptnet_url = 'http://conceptnet.s3.amazonaws.com/precomputed-data/2016/numberbatch/17.06/mini.h5'\n",
    "    urlretrieve(conceptnet_url, 'datasets/mini.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the `mini.h5` file. \n",
    "We extract from the file a list of utf-8-encoded words, as well as their 300-d vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_words dimensions: 362891\n",
      "all_embeddings dimensions: (362891, 300)\n",
      "Random example word: /c/de/aufmachung\n"
     ]
    }
   ],
   "source": [
    "# Load the file and pull out words and embeddings\n",
    "import h5py\n",
    "\n",
    "with h5py.File('datasets/mini.h5', 'r') as f:\n",
    "    all_words = [word.decode('utf-8') for word in f['mat']['axis1'][:]]\n",
    "    all_embeddings = f['mat']['block0_values'][:]\n",
    "    \n",
    "print(\"all_words dimensions: {}\".format(len(all_words)))\n",
    "print(\"all_embeddings dimensions: {}\".format(all_embeddings.shape))\n",
    "\n",
    "print(\"Random example word: {}\".format(all_words[1337]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`all_words` is a list of $V$ strings (what we call our *vocabulary*), and `all_embeddings` is a $V \\times 300$ matrix. The strings are of the form `/c/language_code/word`â€”for example, `/c/en/cat` and `/c/es/gato`.\n",
    "\n",
    "Extract only English words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of English words in all_words: 150875\n",
      "english_embeddings dimensions: (150875, 300)\n",
      "activated_carbon\n"
     ]
    }
   ],
   "source": [
    "# Restrict our vocabulary to just the English words\n",
    "english_words = [word[6:] for word in all_words if word.startswith('/c/en/')]\n",
    "english_word_indices = [i for i, word in enumerate(all_words) if word.startswith('/c/en/')]\n",
    "english_embeddings = all_embeddings[english_word_indices]\n",
    "\n",
    "print(\"Number of English words in all_words: {0}\".format(len(english_words)))\n",
    "print(\"english_embeddings dimensions: {0}\".format(english_embeddings.shape))\n",
    "\n",
    "print(english_words[1337])"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The magnitude of a word vector can be thought of as representing frequency of use, independent of the semantics of the word. \n",
    "\n",
    "We have to *normalize* vectors, dividing each by its length. \n",
    "The result is that all of our word vectors are length 1, and as such, lie on a unit circle. \n",
    "The dot product of two vectors is proportional to the cosine of the angle between them, and provides a measure of similarity (the bigger the cosine, the smaller the angle).\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "norms = np.linalg.norm(english_embeddings, axis=1)\n",
    "normalized_embeddings = english_embeddings.astype('float32') / norms.astype('float32').reshape([-1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to look up words easily, so we create a dictionary that maps us from a word to its index in the word embeddings matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = {word: i for i, word in enumerate(english_words)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure similarity between pairs of words by taking dot products of 2 vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\tcat\t 1.0\n",
      "cat\tfeline\t 0.8199548\n",
      "cat\tdog\t 0.590724\n",
      "cat\tmoo\t 0.0039538266\n",
      "cat\tfreeze\t -0.030225186\n",
      "antonym\topposite\t 0.3941065\n",
      "antonym\tsynonym\t 0.46883982\n"
     ]
    }
   ],
   "source": [
    "def similarity_score(w1, w2):\n",
    "    score = np.dot(normalized_embeddings[index[w1], :], normalized_embeddings[index[w2], :])\n",
    "    return score\n",
    "\n",
    "# A word is as similar with itself as possible:\n",
    "print('cat\\tcat\\t', similarity_score('cat', 'cat'))\n",
    "\n",
    "# Closely related words still get high scores:\n",
    "print('cat\\tfeline\\t', similarity_score('cat', 'feline'))\n",
    "print('cat\\tdog\\t', similarity_score('cat', 'dog'))\n",
    "\n",
    "# Unrelated words, not so much\n",
    "print('cat\\tmoo\\t', similarity_score('cat', 'moo'))\n",
    "print('cat\\tfreeze\\t', similarity_score('cat', 'freeze'))\n",
    "\n",
    "# Antonyms are still considered related, sometimes more so than synonyms\n",
    "print('antonym\\topposite\\t', similarity_score('antonym', 'opposite'))\n",
    "print('antonym\\tsynonym\\t', similarity_score('antonym', 'synonym'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can also find the most similar words to a given word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat', 'humane_society', 'kitten', 'feline', 'colocolo', 'cats', 'kitty', 'maine_coon', 'housecat', 'sharp_teeth']\n",
      "['dog', 'dogs', 'wire_haired_dachshund', 'doggy_paddle', 'lhasa_apso', 'good_friend', 'puppy_dog', 'bichon_frise', 'woof_woof', 'golden_retrievers']\n",
      "['duke', 'dukes', 'duchess', 'duchesses', 'ducal', 'dukedom', 'duchy', 'voivode', 'princes', 'prince']\n"
     ]
    }
   ],
   "source": [
    "def closest_to_vector(v, n):\n",
    "    all_scores = np.dot(normalized_embeddings, v)\n",
    "    best_words = list(map(lambda i: english_words[i], reversed(np.argsort(all_scores))))\n",
    "    return best_words[:n]\n",
    "\n",
    "def most_similar(w, n):\n",
    "    return closest_to_vector(normalized_embeddings[index[w], :], n)\n",
    "\n",
    "print(most_similar('cat', 10))\n",
    "print(most_similar('dog', 10))\n",
    "print(most_similar('duke', 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can also use `closest_to_vector` to find words \"nearby\" vectors that we create ourselves. This allows us to solve analogies. \n",
    "\n",
    "For example, in order to solve the analogy \"man : brother :: woman : ?\", we can compute a new vector `brother - man + woman`: the meaning of brother, minus the meaning of man, plus the meaning of woman. We can then ask which words are closest, in the embedding space, to that new vector.\n",
    "\n",
    "<sup>* Results might not be perfect</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sister']\n",
      "['wife']\n",
      "['paris']\n",
      "['fish']\n",
      "['dog']\n",
      "['ice']\n"
     ]
    }
   ],
   "source": [
    "def solve_analogy(a1, b1, a2):\n",
    "    b2 = normalized_embeddings[index[b1], :] - normalized_embeddings[index[a1], :] + normalized_embeddings[index[a2], :]\n",
    "    return closest_to_vector(b2, 1)\n",
    "\n",
    "print(solve_analogy(\"man\", \"brother\", \"woman\"))\n",
    "print(solve_analogy(\"man\", \"husband\", \"woman\"))\n",
    "print(solve_analogy(\"spain\", \"madrid\", \"france\"))\n",
    "print(solve_analogy(\"bird\", \"wing\", \"fish\"))\n",
    "print(solve_analogy(\"cat\", \"kitten\", \"dog\"))\n",
    "print(solve_analogy(\"fire\", \"hot\", \"ice\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using embeddings in models\n",
    "\n",
    "Primary use of word embeddings is that they allow us to think of words as existing in a continuous, Euclidean space; then can use machine learning with continuous numerical data (like logistic regression or neural networks) to process text.\n",
    "\n",
    "To demonstrate this perform sentiment analysis on movie reviews.\n",
    "\n",
    "Use a [Simple Word Embedding Model](http://people.ee.duke.edu/~lcarin/acl2018_swem.pdf) (SWEM, Shen et al. 2018) to do so. \n",
    "We will represent a review as the mean of the embeddings of the words in the review. \n",
    "Then we'll train a two-layer MLP (a neural network) to classify the review as positive or negative.\n",
    "\n",
    "Download the `movie-simple.txt` file. \n",
    "Each line of that file contains \n",
    "\n",
    "1. the numeral 0 (for negative) or the numeral 1 (for positive), followed by\n",
    "2. a tab (the whitespace character), and then\n",
    "3. the review itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of inputs: (1411, 300)\n",
      "Shape of labels: (1411, 1)\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "remove_punct=str.maketrans('','',string.punctuation)\n",
    "\n",
    "# This function converts a line of our data file into\n",
    "# a tuple (x, y), where x is 300-dimensional representation\n",
    "# of the words in a review, and y is its label.\n",
    "def convert_line_to_example(line):\n",
    "    # Pull out the first character: that's our label (0 or 1)\n",
    "    y = int(line[0])\n",
    "    \n",
    "    # Split the line into words using Python's split() function\n",
    "    words = line[2:].translate(remove_punct).lower().split()\n",
    "    \n",
    "    # Look up the embeddings of each word, ignoring words not\n",
    "    # in our pretrained vocabulary.\n",
    "    embeddings = [normalized_embeddings[index[w]] for w in words\n",
    "                  if w in index]\n",
    "    \n",
    "    # Take the mean of the embeddings\n",
    "    x = np.mean(np.vstack(embeddings), axis=0)\n",
    "    return x, y\n",
    "\n",
    "# Apply the function to each line in the file.\n",
    "xs = []\n",
    "ys = []\n",
    "with open(\"datasets/movie-simple.txt\", \"r\", encoding='utf-8', errors='ignore') as f:\n",
    "    for l in f.readlines():\n",
    "        x, y = convert_line_to_example(l)\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "\n",
    "# Concatenate all examples into a numpy array\n",
    "xs = np.vstack(xs)\n",
    "ys = np.vstack(ys)\n",
    "\n",
    "print(\"Shape of inputs: {}\".format(xs.shape))\n",
    "print(\"Shape of labels: {}\".format(ys.shape))\n",
    "\n",
    "num_examples = xs.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like this, input words have been converted to vectors as part of our preprocessing.\n",
    "This essentially locks our word embeddings in place throughout training, as opposed to learning the word embeddings.\n",
    "\n",
    "Learning word embeddings from scratch/fine-tuned from pre-trained initialization is often better as it is more specialized, but not needed here as dataset is small.\n",
    "\n",
    "Next, split data into test/train set, then convert to tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 20 labels before shuffling: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "First 20 labels after shuffling: [1 1 0 1 0 0 0 1 1 1 0 1 0 1 0 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Shuffle the data\n",
    "print(\"First 20 labels before shuffling: {0}\".format(ys[:20, 0]))\n",
    "\n",
    "shuffle_idx = np.random.permutation(num_examples)\n",
    "xs = xs[shuffle_idx, :]\n",
    "ys = ys[shuffle_idx, :]\n",
    "\n",
    "print(\"First 20 labels after shuffling: {0}\".format(ys[:20, 0]))\n",
    "\n",
    "# Split the data into training and test sets (80-20)\n",
    "num_train = 4*num_examples // 5\n",
    "\n",
    "x_train = torch.tensor(xs[:num_train])\n",
    "y_train = torch.tensor(ys[:num_train], dtype=torch.float32)\n",
    "\n",
    "x_test = torch.tensor(xs[num_train:])\n",
    "y_test = torch.tensor(ys[num_train:], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a TensorDataset and DataLoader (like in MNIST):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_train = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "reviews_test = torch.utils.data.TensorDataset(x_test, y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(reviews_train, batch_size=100, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(reviews_test, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building SVEM Model:\n",
    "\n",
    "Notice that number of outputs for our MLP can be made to 2 (1 each for diff output classes positive/negative).\n",
    "However, since we only have two output classes here, we can instead produce a single output value, calling everything greater than $0$ \"postive\" and everything less than $0$ \"negative\".\n",
    "\n",
    "Then pass this output through a sigmoid operation, values are mapped to $[0,1]$, with $0.5$ being the classification threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SWEM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(300, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model:\n",
    "\n",
    "Notice that since we are doing binary classification we use binary cross-entropy (BCE) loss instead of cross-entropy loss, and we use \"with logits\" version for numerical stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \t Train Loss: 0.6989526748657227 \t Train Acc: 0.539893627166748\n",
      "Epoch: 25 \t Train Loss: 0.14925622940063477 \t Train Acc: 0.9459219574928284\n",
      "Epoch: 50 \t Train Loss: 0.09281475841999054 \t Train Acc: 0.9707446694374084\n",
      "Epoch: 75 \t Train Loss: 0.149235337972641 \t Train Acc: 0.9769503474235535\n",
      "Epoch: 100 \t Train Loss: 0.06615883111953735 \t Train Acc: 0.9804964661598206\n",
      "Epoch: 125 \t Train Loss: 0.03409971669316292 \t Train Acc: 0.9831560254096985\n",
      "Epoch: 150 \t Train Loss: 0.08047468215227127 \t Train Acc: 0.9858155846595764\n",
      "Epoch: 175 \t Train Loss: 0.10049691051244736 \t Train Acc: 0.991134762763977\n",
      "Epoch: 200 \t Train Loss: 0.026480156928300858 \t Train Acc: 0.993794322013855\n",
      "Epoch: 225 \t Train Loss: 0.026486586779356003 \t Train Acc: 0.9955673813819885\n",
      "Test accuracy: 0.9611307382583618\n"
     ]
    }
   ],
   "source": [
    "## Training\n",
    "# Instantiate model\n",
    "model = SWEM()\n",
    "\n",
    "# Binary cross-entropy (BCE) Loss and Adam Optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Iterate through train set minibatchs \n",
    "for epoch in range(250):\n",
    "    correct = 0\n",
    "    num_examples = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        # Zero out the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        y = model(inputs)\n",
    "        loss = criterion(y, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        predictions = torch.round(torch.sigmoid(y))\n",
    "        correct += torch.sum((predictions == labels).float())\n",
    "        num_examples += len(inputs)\n",
    "    \n",
    "    # Print training progress\n",
    "    if epoch % 25 == 0:\n",
    "        acc = correct/num_examples\n",
    "        print(\"Epoch: {0} \\t Train Loss: {1} \\t Train Acc: {2}\".format(epoch, loss, acc))\n",
    "\n",
    "## Testing\n",
    "correct = 0\n",
    "num_test = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Iterate through test set minibatchs \n",
    "    for inputs, labels in test_loader:\n",
    "        # Forward pass\n",
    "        y = model(inputs)\n",
    "        \n",
    "        predictions = torch.round(torch.sigmoid(y))\n",
    "        correct += torch.sum((predictions == labels).float())\n",
    "        num_test += len(inputs)\n",
    "    \n",
    "print('Test accuracy: {}'.format(correct/num_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment of the word 'exciting': positive (sigmoid output: 0.9999997615814209)\n",
      "Sentiment of the word 'hated': negative (sigmoid output: 6.418668360615355e-23)\n",
      "Sentiment of the word 'boring': negative (sigmoid output: 1.2959721552637778e-17)\n",
      "Sentiment of the word 'loved': positive (sigmoid output: 1.0)\n",
      "Sentiment of the word 'alright': negative (sigmoid output: 0.06384996324777603)\n",
      "Sentiment of the word 'decent': negative (sigmoid output: 0.01869584619998932)\n",
      "Sentiment of the word 'terrible': negative (sigmoid output: 7.299112552507866e-19)\n",
      "Sentiment of the word 'awesome': positive (sigmoid output: 1.0)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "words_to_test = [\"exciting\", \"hated\", \"boring\", \"loved\", \"alright\", \"decent\", \"terrible\", \"awesome\"]\n",
    "\n",
    "for word in words_to_test:\n",
    "    x = torch.tensor(normalized_embeddings[index[word]].reshape(1, 300))\n",
    "    sigmoid_output = torch.sigmoid(model(x)).item() # model(x) returns a tensor, .item() gets the float value\n",
    "    \n",
    "    if sigmoid_output < 0.3:\n",
    "        sentiment = \"negative\"\n",
    "    elif sigmoid_output > 0.7:\n",
    "        sentiment = \"positive\"\n",
    "    else:\n",
    "        sentiment = \"neutral\"\n",
    "    \n",
    "    print(\"Sentiment of the word '{0}': {1} (sigmoid output: {2})\".format(word, sentiment, sigmoid_output))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Word Embeddings\n",
    "\n",
    "Pre-trained word embeddings are typically trained on large corpora with unsupervised objectives, and are often non-specific.\n",
    "If we have enough data, we may prefer to learn the word embeddings, either from scratch or with fine-tuning, as making them specific to the task may improve performance.\n",
    "\n",
    "To learn word embeddings we need to make them a part of our model, rather than as part of loading the data.\n",
    "\n",
    "Use `nn.Embedding`.\n",
    "\n",
    "Like the other `nn` layers we've seen (e.g. `nn.Linear`), `nn.Embedding` must be instantiated first. \n",
    "\n",
    "There are two required arguments for instantiation: number of embeddings (i.e. the vocabulary size $V$) and the dimension of word embeddings (300, in our previous example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000, 300])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE = 5000\n",
    "EMBED_DIM = 300\n",
    "\n",
    "embedding = nn.Embedding(VOCAB_SIZE, EMBED_DIM)\n",
    "\n",
    "embedding.weight.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a word embedding matrix that is $5000 \\times 300$, basically a 300 dimensional word embedding for each of the 5000 words, stacked on top of each other.\n",
    "Looking up a word embedding in this embedding matrix is simply selecting a specific row of this matrix, corresponding to the word.\n",
    "\n",
    "When word embeddings are learned, `nn.Embedding` look-up is often one of the first operations in a model module.\n",
    "For example, if we were to learn the word embeddings for our previous SWEM model, the model might instead look like this:\n",
    "\n",
    "* Note that the expected input to the `forward()` function is now the word tokens for the input sentence, so we would have to modify our data input pipeline as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SWEMWithEmbeddings(\n",
      "  (embedding): Embedding(5000, 300)\n",
      "  (fc1): Linear(in_features=300, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class SWEMWithEmbeddings(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_dim, num_outputs):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.fc1 = nn.Linear(embedding_size, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, num_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = torch.mean(x, dim=0)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "# size of layers have been abstracted out to the constructor\n",
    "model = SWEMWithEmbeddings(\n",
    "    vocab_size = 5000,\n",
    "    embedding_size = 300, \n",
    "    hidden_dim = 64, \n",
    "    num_outputs = 1,\n",
    ")\n",
    "print(model)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent Neural Networks (RNNs)\n",
    "\n",
    "Sequential data is commonly modeled with RNNs. Since natural language is viewed as a sequence of words, RNNs are commonly used for NLP.\n",
    "\n",
    "RNNs use combinations of linear and nonlinear transformations to project input into higher level representations, and these representations can be stacked with additional layers.\n",
    "\n",
    "#### Sentences as Sequences\n",
    "\n",
    "Difference between sequential models and the other models we've seen is the presence of a \"time\" dimension: words in a sentence (or paragraph, document) have an ordering to them that convey meaning:\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "In the example sequence above, the word \"Recurrent\" is the $t=1$ word, which we denote $w_1$; similarly, \"neural\" is $w_2$, and so on.\n",
    "\n",
    "It is advantageous to model words as embedding vectors $x_1, ..., x_T$, rather than one-hot vectors (which tokens $w_1,...w_T$ correspond to), so our first step is often to do an embedding table look-up for each input word.\n",
    "\n",
    "Assume 300-dimensional word embeddings and, for simplicity, a minibatch of size 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xs shape: torch.Size([5, 1, 300])\n"
     ]
    }
   ],
   "source": [
    "mb = 1\n",
    "x_dim = 300 \n",
    "sentence = [\"recurrent\", \"neural\", \"networks\", \"are\", \"great\"]\n",
    "\n",
    "xs = []\n",
    "for word in sentence:\n",
    "    xs.append(torch.tensor(normalized_embeddings[index[word]]).view(1, x_dim))\n",
    "    \n",
    "xs = torch.stack(xs, dim=0)\n",
    "print(\"xs shape: {}\".format(xs.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we have formatted our inputs as ($\\text{words} \\times \\text{minibatch} \\times \\text{embedding dimension}$).\n",
    "This is the preferred input ordering for PyTorch RNNs.\n",
    "\n",
    "Let's say we want to process this example.\n",
    "In our previous sentiment analysis example, we just took the average embedding across time, treating the input as a \"bag-of-words.\"\n",
    "For simple problems, this can work surprisingly well, but as you might imagine, the ordering of words in a sentence is often important, and sometimes, we'd like to be able to model this temporal meaning as well.\n",
    "Enter RNNs.\n"
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "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"
    },
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHwAAAAoCAYAAAA8AZ5fAAAF90lEQVR4Ae2av2vbWhTH75+h1dAl0CHeorGGDhF4qCGLIEMwHYLpJDoU8xYjOgSRybwhiAwP5CGgDgW9IaAuAWUoKEPBGQLqkEFDBw0eNGT4Pq5++epnJDcvjZECxtdX0r3nns8953uuCEH31yoPkFattlssOuAt2wQd8A54yzzQsuV2Ed4Bb5kHWrbcLsI74C3zQMuW20V4B7xlHmjZcrsI74C3zAMtW24X4R3wlnmgZcvtIrwDnvWAD+dSwWQ4AP+Kh3KTvf68v70rBaP9Mcb7BL1PJnxmev9Wgzwz4DJ9lU3Xhv5ZAEcICCEQZgaWvzy4Nya0T3zQRwiPybkFZxWP5MO7VTGmz3ACpgv6THztCb89B8apiMFeD/0Tez3wwxLqsQxzwzlrRrgH45iA7MqwWA+vzXie1o0CnghQblyYfw0wONYTuP61jMGhBqexJRamAfB+ejP/1DCi/UVrpnZw1I7/1xne1wkI6UP65qVXtbIgvxGh/Ux31/lVE3jklCMdmanrzPFE90Sb7kBLICcD/9QgvpJgJlGYXKnRsCAXAPevpugHwBUw8QX4NuQ9DsL5ssbY8S0elt9M2PfNNog140DICNp9PA7zfadC2JNhNxuy5j9A3CjB4oXz5vHDmPh7zV96kEbzNnjQj0g67TWaqQB4ADVM82SXBe7DmvHoH+sNM0k4x2hRW2wA2FB2Cci+WjJXuO68P6oXXyvC3cUoSC3ydcPtVD13zaserHMF0pDudoL+4RTqpbvWbrrTCcH0qmS4VcZm34OXygR54PYpD34o5CI8iPq9CYzGqXQD4PehpOy8m2A83AFHOAxmZirDOv+MkN6QJT5gumsA92F+pAXKBIbnY7mQILyKfzMjMU1rFkVHkCor2jOLeaqqGdmwK8HMaIp7IYZpLwPBvZxD+RgWZNwHI3CUczFGj9rESTAS6BngVJ8p1KtYw6MIX5mQOD6vp1VmJ9eaA/cvpWCD8x80LD0f9gktInnMfySDAlfTIBCbFNI1gFuQOQJyMId+Ooa0sKF/ohAFqHfM5Gxz5cHzanwSp7MPF7VjG/L6bX+u0DkAzpkAQjjI5ypEmop9H34q6FngDtT9PiZfHCCKsDCCXOiHHIQTe51Zisws7WsOPNRvAeptNOi1HGyAyVdmxxf1ldoQXngc+J2KQRCpHIRTumAX2gEB2WO17ZFZfvdyZEORXoXZpKSwofNG2k9KU3EMfAfjoxG4uNJngOsLEb2hArvuBo1AUAmq/BQVoIGvHKhv0/odRnwfKVmN5mlSGzwKPEyZZO0Iz8CEaunMKt/tTxzhcQ1RlLoCHSurZCPnae+o4yWYqciOd2EMPDxXJxEVAw8kQMC8yRHswc9kOCM4+o3Olpn+QoMAV4dIfcycv4OIp5LGnr8j4NJlyTjxEpnvR4BH2knTd5Ra4p2WOxsygz6thpfrdzDltRwUNPJ3xgCm6SzGGB2EWi5eFFXJMfDMUSsBHqV4ZszmzWYpPefjoH4gUYZdzx6e0yuy2/rWpPUIcDvS77V2hpopQj6bQ/3O6Eky5FM3Qv3mjsPCKz96eHxJpbUHF/aNC++HivGRBuchOuLsKrDuNEz/Zs/QIQxuOE+faSPg/Aej5FiUt6S8pxnwdF3iBUdBrkBS7NN+xbGt2Jpq4DntdGG874F7LUK5eg7YAIJ3AByKozNcFJUdjjmvev9K2OF6EI7nsKIU6H4ZB32jmZkBSGEUvDWjwKnuF730KPZlRW8z4N4PDdJwAPGjAulogPFMxzJXP9BNnNH0CgviS9XA47v+4LdzNgDJalfOHgfaYQ+pCjZ3z5/scGCcKFCvny5IaO3CV9VRJct9mcDvdUzeDqB8s6DscRAXNd7wrZZQ34+h3tYvYEp88uK7vcspxqd26iVMXaNfJvBfBqTXHPg3AsQTq8HCPNhfzfy79rre2Ib7VjbM36idXibwbXD8ltrYAd9ScJua3QHf1HNb+lwHfEvBbWp2B3xTz23pcx3wLQW3qdkd8E09t6XPdcC3FNymZnfAN/Xclj73H4ZvQsgHzvDPAAAAAElFTkSuQmCC"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fully Connected Layer\n",
    "\n",
    "Notation has been changed from logistic regression/MLP:\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Instead of calling the result of the fully connected layer $y$, we call it $h$, for hidden state.\n",
    "The variable $y$ is usually reserved for the final layer of the neural network; since logistic regression was a single layer, using $y$ was fine. \n",
    "\n",
    "However, if we assume there is more than one layer, it is more common to refer to the intermediate representation as $h$.\n",
    "Note that we also use $f()$ to denote a nonlinear activation function.\n",
    "In the past, we've seen $f()$ as a $\\text{ReLU}$, but this could also be a $\\sigma()$ or $\\tanh()$ nonlinearity.\n",
    "Visualized:\n",
    "\n",
    "![image-2.png](attachment:image-2.png)\n",
    "\n",
    "We project the input $x$ with a linear transformation (with $W$ and $b$), and then apply a nonlinearity to the output, giving us $h$.\n",
    "During training, our goal is to learn $W$ and $b$.\n"
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "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"
    },
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic RNN\n",
    "\n",
    "Sequential data have multiple inputs $x_1, ..., x_T$, instead of a single $x$ so\n",
    "we need to adapt our models accordingly for an RNN.\n",
    "While there are several variations, a common basic formulation for an RNN is the Elman RNN:\n",
    "\n",
    "\\begin{align}\n",
    "h_t = \\tanh((x_t W_x + b_x) + (h_{t-1} W_h + b_h))\n",
    "\\end{align}\n",
    "\n",
    "where $\\tanh()$ is the hyperbolic tangent, a nonlinear activation function.\n",
    "RNNs process words one at a time in sequence ($x_t$), producing a hidden state $h_t$ at every time step.\n",
    "The first half of the above equation should look familiar; as with the fully connected layer, we are linearly transforming each input $x_t$, and then applying a nonlinearity.\n",
    "Notice that we apply the same linear transformation ($W_x$, $b_x$) at every time step.\n",
    "The difference is that we also apply a separate linear transform ($W_h$, $b_h$) to the previous hidden state $h_{t-1}$ and add it to our projected input.\n",
    "This feedback is called a *recurrent* connection.\n",
    "\n",
    "These directed cycles in the RNN architecture gives them the ability to model temporal dynamics, making them particularly suited for modeling sequences (e.g. text).\n",
    "We can visualize an RNN layer as follows:\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Showing multiple sequences:\n",
    "\n",
    "![image-2.png](attachment:image-2.png)\n",
    "\n",
    "These recurrent connections allows the model to consider previous hidden states of a sequence when calculating the hidden state for the current input.\n",
    "\n",
    "<font size=\"1\">&ast;Note: We don't actually need two separate biases $b_x$ and $b_h$, as you can combine both biases into a single learnable parameter $b$. \n",
    "However, writing it separately helps make it clear that we're performing a linear transformation on both $x_t$ and $h_{t-1}$.\n",
    "Speaking of combining variables, we can also express the above operation by concatenating $x_t$ and $h_{t-1}$ into a single vector $z_t$, and then performing a single matrix multiply $z_t W_z + b$, where $W_z$ is essentially $W_x$ and $W_h$ concatenated.\n",
    "Indeed this is how many \"official\" RNNs modules are implemented, as the reduction in the number of separate matrix multiply operations makes it computationally more effecient.\n",
    "These are implementation details though.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN in PyTorch\n",
    "\n",
    "In an RNN, we project both the input $x_t$ and the previous hidden state $h_{t-1}$ to some hidden dimension, which we choose to be 128.\n",
    "To perform these operations, we're going to define some variables we're going to learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([300, 128]) torch.Size([128]) torch.Size([128, 128]) torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "h_dim = 128 # hidden dimension size of the RNN\n",
    "\n",
    "# For projecting the input\n",
    "Wx = torch.randn(x_dim, h_dim)/np.sqrt(x_dim)\n",
    "Wx.requires_grad_()\n",
    "bx = torch.zeros(h_dim, requires_grad=True)\n",
    "\n",
    "# For projecting the previous state\n",
    "Wh = torch.randn(h_dim, h_dim)/np.sqrt(h_dim)\n",
    "Wh.requires_grad_()\n",
    "bh = torch.zeros(h_dim, requires_grad=True)\n",
    "\n",
    "print(Wx.shape, bx.shape, Wh.shape, bh.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, we define a function for one time step of the RNN.\n",
    "This function take the current input $x_t$ and previous hidden state $h_{t-1}$, performs the linear transformations $x W_x + b_x$ and $h W_h + b_h$, and then a hyperbolic tangent nonlinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN_step(x, h):\n",
    "    h_next = torch.tanh((torch.matmul(x, Wx) + bx) + (torch.matmul(h, Wh) + bh))\n",
    "\n",
    "    return h_next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each step of our RNN is going to require feeding in an input (i.e. the word representation) and the previous hidden state (the summary of preceding sequence). Note that at the beginning of a sentence, we don't have a previous hidden state, so we initialize it to some value, for example all zeros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word embedding for first word\n",
    "x1 = xs[0, :, :]\n",
    "\n",
    "# Initialize hidden state to 0\n",
    "h0 = torch.zeros([mb, h_dim])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To take one time step of the RNN, we call the function we wrote, passing in $x_1$ and $h_0$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden state h1 dimensions: torch.Size([1, 128])\n"
     ]
    }
   ],
   "source": [
    "# Forward pass of one RNN step for time step t=1\n",
    "h1 = RNN_step(x1, h0)\n",
    "\n",
    "print(\"Hidden state h1 dimensions: {0}\".format(h1.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then call the `RNN_step` function again to get the next time step output from our RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden state h2 dimensions: torch.Size([1, 128])\n"
     ]
    }
   ],
   "source": [
    "# Word embedding for second word\n",
    "x2 = xs[1, :, :]\n",
    "\n",
    "# Forward pass of one RNN step for time step t=2\n",
    "h2 = RNN_step(x2, h1)\n",
    "\n",
    "print(\"Hidden state h2 dimensions: {0}\".format(h2.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can continue unrolling the RNN as far as we need to. \n",
    "For each step, we feed in the current input ($x_t$) and previous hidden state ($h_{t-1}$) to get a new output.\n",
    "\n",
    "However instead of doing it manually use `torch.nn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN parameter shapes: [torch.Size([128, 300]), torch.Size([128, 128]), torch.Size([128]), torch.Size([128])]\n",
      "Hidden states shape: torch.Size([5, 1, 128])\n",
      "Final hidden state shape: torch.Size([1, 1, 128])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn\n",
    "\n",
    "rnn = nn.RNN(x_dim, h_dim)\n",
    "print(\"RNN parameter shapes: {}\".format([p.shape for p in rnn.parameters()]))\n",
    "\n",
    "hs, h_T = rnn(xs) # pass entire input sequence xs, returns all hidden states and the final hidden state\n",
    "\n",
    "print(\"Hidden states shape: {}\".format(hs.shape))\n",
    "print(\"Final hidden state shape: {}\".format(h_T.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do we do with these hidden states?\n",
    "It depends on the model and task.\n",
    "Just like multilayer perceptrons and convolutional neural networks, RNNs can be stacked in multiple layers as well.\n",
    "In this case, the outputs $h_1, ..., h_T$ are the sequential inputs to the next layer.\n",
    "If the RNN layer is the final layer, $h_T$ or the mean/max of $h_1, ..., h_T$ can be used as a summary encoding of the data sequence. \n",
    "What is being predicted can also have an impact on what the RNN outputs are ultimately used for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTMs and Gated RNNs\n",
    "\n",
    "RNNs above can successfully model simple sequential data, but they tend to struggle with longer sequences, with [vanishing gradients](https://en.wikipedia.org/wiki/Vanishing_gradient_problem) an especially big problem.\n",
    "\n",
    "Long Short-Term Memory (LSTM) and the Gated Recurrent Unit (GRU) have seen wide use recently in deep learning.\n",
    "[Summary](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
    "Note that \"RNN\" as a name is somewhat overloaded: it can refer to both the basic recurrent model we went over previously, or recurrent models in general (including LSTMs and GRUs).\n",
    "\n",
    "LSTMs and GRUs layers can be created the same way as basic RNN layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM parameters: [torch.Size([512, 300]), torch.Size([512, 128]), torch.Size([512]), torch.Size([512])]\n",
      "GRU parameters: [torch.Size([384, 300]), torch.Size([384, 128]), torch.Size([384]), torch.Size([384])]\n"
     ]
    }
   ],
   "source": [
    "lstm = nn.LSTM(x_dim, h_dim)\n",
    "print(\"LSTM parameters: {}\".format([p.shape for p in lstm.parameters()]))\n",
    "\n",
    "gru = nn.GRU(x_dim, h_dim)\n",
    "print(\"GRU parameters: {}\".format([p.shape for p in gru.parameters()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other resources\n",
    "\n",
    "[Fantastic introduction to LSTMs and GRUs](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
    "\n",
    "[Popular blog post on the effectiveness of RNNs](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Classification\n",
    "\n",
    "The AG News dataset contains text from 127600 online news articles, from 4 different categories: World, Sports, Business, and Science/Technology.\n",
    "AG News is typically used for topic classification: given an unseen news article, we're interested in predicting the topic.\n",
    "\n",
    "We will learn the word embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Dataset\n",
    "\n",
    "1. Load in dataset\n",
    "2. Tokenize text\n",
    "3. Add padding/truncation (as sentence length is not equal) \n",
    "    - Use custom `collator(batch)` and `pad_sequence()` \n",
    "4. Create `DataLoader` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tristan\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchtext\\datasets\\__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "C:\\Users\\tristan\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchtext\\data\\__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "C:\\Users\\tristan\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchtext\\vocab\\__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "C:\\Users\\tristan\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchtext\\utils.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First sequence without padding: (2, [431, 427, 1, 1605, 14836, 113, 66, 2, 848, 13, 27, 14, 27, 15, 50718, 3, 431, 374, 16, 9, 67497, 6, 52251, 3, 42, 4009, 782, 325, 1], 29)\n",
      "Length of the first text example: 29\n",
      "Length of the second text example: 42\n",
      "First sequence padded: tensor([  431,   427,     1,  1605, 14836,   113,    66,     2,   848,    13,\n",
      "           27,    14,    27,    15, 50718,     3,   431,   374,    16,     9,\n",
      "        67497,     6, 52251,     3,    42,  4009,   782,   325,     1,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0])\n",
      "First sequence length: 42\n",
      "Second sequence padded: tensor([15873,  1072,   854,  1310,  4249,    13,    27,    14,    27,    15,\n",
      "          929,   797,   320, 15873,    98,     3, 27655,    28,     5,  4459,\n",
      "           11,   564, 52782,     8, 80609,  2125,     7,     2,   525,   241,\n",
      "            3,    28,  3890, 82806,  6574,    10,   206,   359,     6,     2,\n",
      "          126,     1])\n",
      "Second sequence length: 42\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torchtext\n",
    "from torchtext.datasets import AG_NEWS\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "train_csv_path = './datasets/AG_NEWS/train.csv'\n",
    "test_csv_path = './datasets/AG_NEWS/test.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "\n",
    "# Combine 'Title' and 'Description' columns\n",
    "train_df['Combined'] = train_df['Title'] + ' ' + train_df['Description']\n",
    "test_df['Combined'] = test_df['Title'] + ' ' + test_df['Description']\n",
    "\n",
    "# Tokenize the text data\n",
    "def yield_tokens(data_iter):\n",
    "    for text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_df['Combined']), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n",
    "def text_pipeline(x):\n",
    "    return vocab(tokenizer(x))\n",
    "\n",
    "def label_pipeline(x):\n",
    "    return int(x) - 1\n",
    "\n",
    "# Define the dataset class\n",
    "class AGNewsDataset(Dataset):\n",
    "    def __init__(self, data_df, text_pipeline, label_pipeline):\n",
    "        self.data_df = data_df\n",
    "        self.text_pipeline = text_pipeline\n",
    "        self.label_pipeline = label_pipeline\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.label_pipeline(self.data_df.iloc[idx, 0])  # Assuming label is in the first column\n",
    "        text = self.text_pipeline(self.data_df.iloc[idx, 1] + ' ' + self.data_df.iloc[idx, 2])   # Combining second and third columns\n",
    "        length = len(text) # Store the length of the sequence\n",
    "        return label, text, length\n",
    "\n",
    "# Add collator function for padding\n",
    "def collator(batch):\n",
    "    labels = torch.tensor([example[0] for example in batch], dtype=torch.int64)\n",
    "    sentences = [torch.tensor(example[1], dtype=torch.int64) for example in batch]\n",
    "    lengths = [example[2] for example in batch]  # Extract lengths from the batch\n",
    "    data = pad_sequence(sentences, batch_first=True, padding_value=0)\n",
    "    return data, labels, torch.tensor(lengths, dtype=torch.int64)  # Return lengths as tensor\n",
    "\n",
    "train_dataset = AGNewsDataset(train_df, text_pipeline, label_pipeline)\n",
    "test_dataset = AGNewsDataset(test_df, text_pipeline, label_pipeline)\n",
    "\n",
    "# Create training and validation sets\n",
    "num_train = len(train_dataset)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "split = int(0.8 * num_train)  # 80% for training, 20% for validation\n",
    "train_idx, val_idx = indices[:split], indices[split:]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "val_sampler = SubsetRandomSampler(val_idx)\n",
    "\n",
    "# Create DataLoaders\n",
    "BATCH_SIZE = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=train_sampler, collate_fn=collator)\n",
    "val_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=val_sampler, collate_fn=collator)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collator)\n",
    "\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True, collate_fn=collator)\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=False, collate_fn=collator)\n",
    "\n",
    "print(\"First sequence without padding: {}\".format(train_dataset[0]))\n",
    "\n",
    "print(\"Length of the first text example: {}\".format(len(train_dataset[0][1])))\n",
    "print(\"Length of the second text example: {}\".format(len(train_dataset[1][1])))\n",
    "\n",
    "# Padding demonstration\n",
    "padded_exs = pad_sequence([torch.tensor(train_dataset[0][1], dtype=torch.int64), torch.tensor(train_dataset[1][1], dtype=torch.int64)], batch_first=True)\n",
    "print(\"First sequence padded: {}\".format(padded_exs[0]))\n",
    "print(\"First sequence length: {}\".format(len(padded_exs[0])))\n",
    "print(\"Second sequence padded: {}\".format(padded_exs[1]))\n",
    "print(\"Second sequence length: {}\".format(len(padded_exs[1])))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SWEM \n",
    "\n",
    "This time we learn the embeddings from scratch.\n",
    "\n",
    "Defining more hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 95804\n",
      "Number of labels: 4\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = len(vocab)\n",
    "print(\"Vocabulary size: {}\".format(VOCAB_SIZE))\n",
    "EMBED_DIM = 100\n",
    "HIDDEN_DIM = 64\n",
    "num_labels = len(train_df.iloc[:, 0].unique())\n",
    "print(\"Number of labels: {}\".format(num_labels))\n",
    "NUM_OUTPUTS = num_labels\n",
    "NUM_EPOCHS = 10\n",
    "PATIENCE = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organize our model as a `nn.Module`.\n",
    "Instead of assuming the input is already an embedding, we're going to make learning the embedding as part of our model.\n",
    "Do this by using `nn.Embedding` to perform an embedding look-up at the beginning of our forward pass.\n",
    "Once we've done the look up, we'll have a minibatch of embedded sequences of dimension $L \\times$ `BATCH_SIZE` $\\times$ `EMBED_DIM`.\n",
    "For SWEM, remember, we take the mean across the length dimension to get an average embedding for the sequence.\n",
    "\n",
    "<font size=\"1\"> \n",
    "&ast;Note: Technically we should only take the mean across the embeddings at the positions corresponding to \"real\" words in our input, and not for the zero paddings we artificially added.\n",
    "This can be done by generating a binary mask while doing the padding to track the \"real\" words in the input.\n",
    "Ultimately though, this refinement doesn't have much impact on the results for this particular task, so we omit it for simplicity.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "class SWEM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_dim, num_outputs):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        \n",
    "        self.fc1 = nn.Linear(embedding_size, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, num_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embed = self.embedding(x) # (batch_size, seq_len, embedding_dim)\n",
    "        embed_mean = torch.mean(embed, dim=0) # takes mean over the sequence length\n",
    "        \n",
    "        h = self.fc1(embed_mean)\n",
    "        h = F.relu(h)\n",
    "        h = self.fc2(h)\n",
    "        return h\n",
    "    \n",
    "\n",
    "## Training\n",
    "# Instantiate model\n",
    "model = SWEM(\n",
    "    vocab_size = VOCAB_SIZE,\n",
    "    embedding_size = EMBED_DIM, \n",
    "    hidden_dim = HIDDEN_DIM, \n",
    "    num_outputs = NUM_OUTPUTS,\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "# Training with validation and early stopping\n",
    "best_val_loss = float('inf')\n",
    "early_stop_counter = 0\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for data, labels, lengths in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS}\"):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch+1}/{NUM_EPOCHS}, Training Loss: {avg_train_loss:.4f}')\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, labels in val_loader:\n",
    "            output = model(data)\n",
    "            loss = criterion(output, labels)\n",
    "            val_loss += loss.item()\n",
    "            predictions = torch.argmax(output, dim=1)\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = correct / total\n",
    "    print(f'Epoch {epoch+1}/{NUM_EPOCHS}, Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "    # Early stopping\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        early_stop_counter = 0\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "\n",
    "    if early_stop_counter >= PATIENCE:\n",
    "        print(f\"Early stopping at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "# Testing\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data, labels, lengths in tqdm(test_loader, desc=\"Testing\"):\n",
    "        output = model(data)\n",
    "        predictions = torch.argmax(output, dim=1)\n",
    "        correct += (predictions == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "test_accuracy = correct / total\n",
    "print(f'Test accuracy: {test_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 2\n"
     ]
    }
   ],
   "source": [
    "## Testing on single example\n",
    "\n",
    "def prepare_text(text, vocab, tokenizer):\n",
    "    tokens = tokenizer(text)\n",
    "    token_indices = [vocab[token] for token in tokens]\n",
    "    return torch.tensor(token_indices, dtype=torch.long).unsqueeze(1)  # Add batch dimension\n",
    "\n",
    "def classify_text(model, text, vocab, tokenizer):\n",
    "    text_tensor = prepare_text(text, vocab, tokenizer)\n",
    "    with torch.no_grad():\n",
    "        output = model(text_tensor)\n",
    "        predicted_class = torch.argmax(output, dim=1).item()\n",
    "    return predicted_class\n",
    "\n",
    "# Example usage:\n",
    "custom_text = \"The Boston Celtics are winners of the 2024 NBA Championship!\"\n",
    "predicted_class = classify_text(model, custom_text, vocab, tokenizer)\n",
    "print(f\"Predicted class: {predicted_class + 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "# Define the RNN-based model\n",
    "class RNNClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_dim, num_outputs):\n",
    "        super(RNNClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn = nn.RNN(embedding_size, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, num_outputs)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        embed = self.embedding(x) # embedding layer (batch_size, seq_len, embedding_size)\n",
    "        packed_embed = pack_padded_sequence(embed, lengths.cpu(), batch_first=True, enforce_sorted=False)  # pack sequence, ensures RNN only processes non-padded elements\n",
    "        packed_output, ht = self.rnn(packed_embed) # rnn only return ht = hidden states\n",
    "        output, _ = pad_packed_sequence(packed_output, batch_first=True) # unpack sequence, adds back padding\n",
    "        h_t = ht[-1] # get the last hidden state\n",
    "        logits = self.fc(h_t) # fully connected layer\n",
    "        return logits\n",
    "\n",
    "## Training\n",
    "# Instantiate model\n",
    "model = RNNClassifier(\n",
    "    vocab_size = VOCAB_SIZE,\n",
    "    embedding_size = EMBED_DIM, \n",
    "    hidden_dim = HIDDEN_DIM, \n",
    "    num_outputs = NUM_OUTPUTS,\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "# Training with validation and early stopping\n",
    "best_val_loss = float('inf')\n",
    "early_stop_counter = 0\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for data, labels, lengths in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS}\"):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data, lengths)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch+1}/{NUM_EPOCHS}, Training Loss: {avg_train_loss:.4f}')\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, labels, lengths in val_loader:\n",
    "            output = model(data, lengths)\n",
    "            loss = criterion(output, labels)\n",
    "            val_loss += loss.item()\n",
    "            predictions = torch.argmax(output, dim=1)\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = correct / total\n",
    "    print(f'Epoch {epoch+1}/{NUM_EPOCHS}, Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "    # Early stopping\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        early_stop_counter = 0\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "\n",
    "    if early_stop_counter >= PATIENCE:\n",
    "        print(f\"Early stopping at epoch {epoch+1}\")\n",
    "        break\n",
    "    \n",
    "# Testing\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data, labels, lengths in tqdm(test_loader, desc=\"Testing\"):\n",
    "        output = model(data, lengths)\n",
    "        predictions = torch.argmax(output, dim=1)\n",
    "        correct += (predictions == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "test_accuracy = correct / total\n",
    "print(f'Test accuracy: {test_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 750/750 [03:43<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Training Loss: 0.7047\n",
      "Epoch 1/10, Validation Loss: 0.4179, Validation Accuracy: 0.8587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 750/750 [04:36<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Training Loss: 0.3223\n",
      "Epoch 2/10, Validation Loss: 0.3252, Validation Accuracy: 0.8920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 750/750 [03:41<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Training Loss: 0.2366\n",
      "Epoch 3/10, Validation Loss: 0.3132, Validation Accuracy: 0.8977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 750/750 [03:22<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Training Loss: 0.1844\n",
      "Epoch 4/10, Validation Loss: 0.3134, Validation Accuracy: 0.8978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 750/750 [03:14<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Training Loss: 0.1454\n",
      "Epoch 5/10, Validation Loss: 0.3020, Validation Accuracy: 0.9041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 750/750 [03:18<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Training Loss: 0.1012\n",
      "Epoch 6/10, Validation Loss: 0.3122, Validation Accuracy: 0.9066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 750/750 [03:19<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Training Loss: 0.0928\n",
      "Epoch 7/10, Validation Loss: 0.3209, Validation Accuracy: 0.9060\n",
      "Early stopping at epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:02<00:00, 22.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "# Define the LSTM-based model\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_dim, num_outputs):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, num_outputs)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        embed = self.embedding(x)\n",
    "        packed_embed = pack_padded_sequence(embed, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_output, (ht, _) = self.lstm(packed_embed) # DIFFERENCE FROM RNN | LSTM returns both the hidden state and cell state\n",
    "        output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "        h_t = ht[-1]\n",
    "        logits = self.fc(h_t)\n",
    "        return logits\n",
    "    \n",
    "## Training\n",
    "# Instantiate model\n",
    "model = LSTMClassifier(\n",
    "    vocab_size = VOCAB_SIZE,\n",
    "    embedding_size = EMBED_DIM, \n",
    "    hidden_dim = HIDDEN_DIM, \n",
    "    num_outputs = NUM_OUTPUTS,\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "# Training with validation and early stopping\n",
    "best_val_loss = float('inf')\n",
    "early_stop_counter = 0\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for data, labels, lengths in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS}\"):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data, lengths)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch+1}/{NUM_EPOCHS}, Training Loss: {avg_train_loss:.4f}')\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, labels, lengths in val_loader:\n",
    "            output = model(data, lengths)\n",
    "            loss = criterion(output, labels)\n",
    "            val_loss += loss.item()\n",
    "            predictions = torch.argmax(output, dim=1)\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = correct / total\n",
    "    print(f'Epoch {epoch+1}/{NUM_EPOCHS}, Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "    # Early stopping\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        early_stop_counter = 0\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "\n",
    "    if early_stop_counter >= PATIENCE:\n",
    "        print(f\"Early stopping at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "# Testing\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data, labels, lengths in tqdm(test_loader, desc=\"Testing\"):\n",
    "        output = model(data, lengths)\n",
    "        predictions = torch.argmax(output, dim=1)\n",
    "        correct += (predictions == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "test_accuracy = correct / total\n",
    "print(f'Test accuracy: {test_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gated Recurrent Unit (GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 750/750 [02:44<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Training Loss: 0.6673\n",
      "Epoch 1/10, Validation Loss: 0.3653, Validation Accuracy: 0.8738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 750/750 [02:58<00:00,  4.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Training Loss: 0.2872\n",
      "Epoch 2/10, Validation Loss: 0.3040, Validation Accuracy: 0.8952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 750/750 [03:31<00:00,  3.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Training Loss: 0.2106\n",
      "Epoch 3/10, Validation Loss: 0.3013, Validation Accuracy: 0.9010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 750/750 [03:53<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Training Loss: 0.1615\n",
      "Epoch 4/10, Validation Loss: 0.3116, Validation Accuracy: 0.9021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 750/750 [03:51<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Training Loss: 0.1242\n",
      "Epoch 5/10, Validation Loss: 0.3208, Validation Accuracy: 0.9025\n",
      "Early stopping at epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:02<00:00, 22.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "# Define the RNN-based model\n",
    "class GRUClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_dim, num_outputs):\n",
    "        super(GRUClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.gru = nn.GRU(embedding_size, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, num_outputs)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        embed = self.embedding(x)\n",
    "        packed_embed = pack_padded_sequence(embed, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_output, ht = self.gru(packed_embed)\n",
    "        output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "        h_t = ht[-1]\n",
    "        logits = self.fc(h_t)\n",
    "        return logits\n",
    "    \n",
    "## Training\n",
    "# Instantiate model\n",
    "model = GRUClassifier(\n",
    "    vocab_size = VOCAB_SIZE,\n",
    "    embedding_size = EMBED_DIM, \n",
    "    hidden_dim = HIDDEN_DIM, \n",
    "    num_outputs = NUM_OUTPUTS,\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "# Training with validation and early stopping\n",
    "best_val_loss = float('inf')\n",
    "early_stop_counter = 0\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for data, labels, lengths in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS}\"):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data, lengths)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch+1}/{NUM_EPOCHS}, Training Loss: {avg_train_loss:.4f}')\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, labels, lengths in val_loader:\n",
    "            output = model(data, lengths)\n",
    "            loss = criterion(output, labels)\n",
    "            val_loss += loss.item()\n",
    "            predictions = torch.argmax(output, dim=1)\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = correct / total\n",
    "    print(f'Epoch {epoch+1}/{NUM_EPOCHS}, Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "    # Early stopping\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        early_stop_counter = 0\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "\n",
    "    if early_stop_counter >= PATIENCE:\n",
    "        print(f\"Early stopping at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "# Testing\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data, labels, lengths in tqdm(test_loader, desc=\"Testing\"):\n",
    "        output = model(data, lengths)\n",
    "        predictions = torch.argmax(output, dim=1)\n",
    "        correct += (predictions == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "test_accuracy = correct / total\n",
    "print(f'Test accuracy: {test_accuracy:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
